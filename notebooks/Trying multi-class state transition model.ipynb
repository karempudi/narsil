{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a2ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c67c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, CheckButtons, RadioButtons\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from skimage import io\n",
    "import pickle\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e60e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_to_classes = {\n",
    "    'all_growing': 0,\n",
    "    'partly_growing': 1,\n",
    "    'stopped_growing': 2,\n",
    "    'stopped_fading': 3,\n",
    "    'stopped_vanishing': 4,\n",
    "    'channel_empty': 5\n",
    "}\n",
    "class_to_states = {\n",
    "    0: 'all_growing',\n",
    "    1: 'partly_growing',\n",
    "    2: 'stopped_growing',\n",
    "    3: 'stopped_fading',\n",
    "    4: 'stopped_vanishing',\n",
    "    5: 'channel_empty'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c53e4f",
   "metadata": {},
   "source": [
    "### Data creator using matplotlib widgets\n",
    "\n",
    "Mark the state transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babdc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTransition(object):\n",
    "    \n",
    "    def __init__(self, phaseDir, fileformat='.tiff',\n",
    "                 labels_file='transitions.pickle', frame_rate=1):\n",
    "        \n",
    "        self.phaseDir = phaseDir\n",
    "        self.fileformat = fileformat\n",
    "        self.labelsFile = labels_file\n",
    "        self.frameRate = frame_rate\n",
    "        self.indices = [int(filename.split('.')[0].split('/')[-1]) for filename in \n",
    "                       glob.glob(self.phaseDir + \"*\" + self.fileformat)]\n",
    "        self.indices.sort()\n",
    "        \n",
    "        self.fig, self.ax = plt.subplots(1, 1, num=str(self.phaseDir), figsize=(12, 10))\n",
    "        plt.subplots_adjust(left=0.35, bottom=0.25)\n",
    "        self.axcolor = 'lightgoldenrodyellow'\n",
    "        \n",
    "        self.currentFrame = 0\n",
    "        self.imagesPlot = self.ax.imshow(self.__getitem__(self.currentFrame), cmap='gray')\n",
    "        self.ax.set_title(str(self.currentFrame) + \" _ \" + str(self.currentFrame + self.frameRate))\n",
    "        \n",
    "          \n",
    "        self.previousax =  plt.axes([0.5, 0.025, 0.1, 0.03])\n",
    "        self.previousButton = Button(self.previousax, 'Previous', color=self.axcolor, hovercolor='0.975')\n",
    "        self.previousButton.on_clicked(self.previousDatapoint)\n",
    "        \n",
    "        self.nextax =  plt.axes([0.65, 0.025, 0.1, 0.03])\n",
    "        self.nextButton = Button(self.nextax, 'Next', color=self.axcolor, hovercolor='0.975')\n",
    "        self.nextButton.on_clicked(self.nextDatapoint)\n",
    "        \n",
    "        self.saveax = plt.axes([0.8, 0.025, 0.1, 0.03])\n",
    "        self.saveButton = Button(self.saveax, 'Save', color=self.axcolor, hovercolor='0.875')\n",
    "        self.saveButton.on_clicked(self.save)\n",
    "        \n",
    "        \n",
    "        self.rax = plt.axes([0.05, 0.5, 0.20, 0.25], facecolor=self.axcolor)\n",
    "        self.radioToState = {\n",
    "            '0 : All Growing': 0,\n",
    "            '1 : Partly Growing': 1,\n",
    "            '2 : Stopped Growing': 2,\n",
    "            '3 : Stopped Fading' : 3,\n",
    "            '4 : Stopped Vanishing': 4,\n",
    "            '5 : Channel Empty' : 5\n",
    "        }\n",
    "        self.radio = RadioButtons(self.rax, ('0 : All Growing', '1 : Partly Growing',\n",
    "                                            '2 : Stopped Growing', '3 : Stopped Fading', \n",
    "                                            '4 : Stopped Vanishing', '5 : Channel Empty'))\n",
    "        #self.radio.on_clicked(self.changeState)\n",
    "        \n",
    "        \n",
    "        # the keys will be frame1_frame2 number and value is the state\n",
    "        self.states = {\n",
    "            \n",
    "        }\n",
    "        \n",
    "        \n",
    "        plt.pause(0.01)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if idx + self.frameRate < self.__len__() and idx >= 0:\n",
    "            phaseFilename1 = self.phaseDir + str(self.indices[idx]) + self.fileformat\n",
    "            phaseFilename2 = self.phaseDir + str(self.indices[idx+self.frameRate]) + self.fileformat\n",
    "            img1 = io.imread(phaseFilename1)\n",
    "            img2 = io.imread(phaseFilename2)\n",
    "            \n",
    "            full_img = np.concatenate((img1, img2), axis = 1)\n",
    "            return full_img\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def nextDatapoint(self, buttonPress):\n",
    "        key = str(self.currentFrame) + \"_\" + str(self.currentFrame + self.frameRate)\n",
    "        #print(self.radio.value_selected)\n",
    "        self.states[key] = self.radioToState[self.radio.value_selected]\n",
    "        \n",
    "        print(self.states)\n",
    "        \n",
    "        # get next Image if you are in range\n",
    "        self.currentFrame += 1\n",
    "        nextImage = self.__getitem__(self.currentFrame)\n",
    "        #print(nextImage.shape)\n",
    "        if nextImage is not None:\n",
    "            self.imagesPlot.set_data(nextImage)\n",
    "            self.ax.set_title(str(self.currentFrame) + \" _ \" + str(self.currentFrame + self.frameRate))\n",
    "            self.fig.canvas.draw()\n",
    "        else:\n",
    "            self.currentFrame -= 1\n",
    "            \n",
    "    def previousDatapoint(self, buttonPress):\n",
    "        key = str(self.currentFrame) + \"_\" + str(self.currentFrame + self.frameRate)\n",
    "        #print(self.radio.value_selected)\n",
    "        self.states[key] = self.radioToState[self.radio.value_selected]\n",
    "        \n",
    "        print(self.states)\n",
    "        \n",
    "        # get next Image if you are in range\n",
    "        self.currentFrame -= 1\n",
    "        previousImage = self.__getitem__(self.currentFrame)\n",
    "        #print(nextImage.shape)\n",
    "        if previousImage is not None:\n",
    "            self.imagesPlot.set_data(previousImage)\n",
    "            self.ax.set_title(str(self.currentFrame) + \" _ \" + str(self.currentFrame + self.frameRate))\n",
    "            self.fig.canvas.draw()\n",
    "        else:\n",
    "            self.currentFrame += 1\n",
    "    \n",
    "    def save(self, save):\n",
    "        print(self.states)\n",
    "        saveFilename = self.phaseDir + self.labelsFile\n",
    "        with open(saveFilename, 'wb') as f:\n",
    "            pickle.dump(self.states, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        print(f\"File save: {saveFilename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2909662c",
   "metadata": {},
   "source": [
    "### Generate training data one stack at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78676129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phaseDir = '/home/pk/Documents/trainingData/deadalive1/40/'\n",
    "#markStates = StateTransition(phaseDir, frame_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2370d6",
   "metadata": {},
   "source": [
    "#### Dataset bundling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03b5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class statesDataset(object):\n",
    "    \n",
    "    def __init__(self, phaseDirectoriesList, fileformat='.tiff', \n",
    "                 transforms=None, class_to_states = {\n",
    "                        0: 'all_growing', 1: 'partly_growing',\n",
    "                        2: 'stopped_growing',3: 'stopped_fading',\n",
    "                        4: 'stopped_vanishing',5: 'channel_empty'}):\n",
    "        self.phaseDirectoriesList = phaseDirectoriesList\n",
    "        self.fileformat = fileformat\n",
    "        self.transforms = transforms\n",
    "        self.classToStates = class_to_states\n",
    "        self.nClasses = len(class_to_states)\n",
    "        \n",
    "        self.data = {} # each class has it's value as key and the values is a list of 2 filename tuples\n",
    "        \n",
    "        self.all_data = []\n",
    "        \n",
    "        for directory in self.phaseDirectoriesList:\n",
    "            statesFilename = directory + 'transitions.pickle'\n",
    "            with open(statesFilename, 'rb') as file:\n",
    "                states = pickle.load(file)\n",
    "            for key, value in states.items():\n",
    "                file1 = directory + key.split('_')[0] + self.fileformat\n",
    "                file2 = directory + key.split('_')[1] + self.fileformat\n",
    "                if value in self.data:\n",
    "                    self.data[value].append((file1, file2))\n",
    "                else:\n",
    "                    self.data[value] = [(file1, file2)]\n",
    "                \n",
    "                self.all_data.append((file1, file2, value))\n",
    "        \n",
    "        classStats = self.classStatistics()\n",
    "        self.weights = np.ones(shape=(self.nClasses,))\n",
    "        for key in classStats:\n",
    "            self.weights[key] /= classStats[key]\n",
    "                    \n",
    "    \n",
    "    def __len__(self):\n",
    "        #length = 0\n",
    "        #for key in self.data:\n",
    "        #    length += len(self.data[key])\n",
    "        #return length\n",
    "        return len(self.all_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        datapoint = self.all_data[idx]\n",
    "        \n",
    "        img1 = io.imread(datapoint[0])\n",
    "        img2 = io.imread(datapoint[1])\n",
    "        label = datapoint[2]\n",
    "        \n",
    "        sample = {\n",
    "            'frame1': img1,\n",
    "            'frame2': img2,\n",
    "            'label': label\n",
    "        }\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def classStatistics(self):\n",
    "        statistics = {}\n",
    "        for key in self.data:\n",
    "            statistics[key] = len(self.data[key])\n",
    "            \n",
    "        return statistics\n",
    "    \n",
    "    def calculateWeights(self):\n",
    "        pass\n",
    "    \n",
    "    def plotDatapoint(self, idx):\n",
    "        \n",
    "        datapoint = self.__getitem__(idx)\n",
    "        \n",
    "        pltImage = np.concatenate((datapoint['frame1'], datapoint['frame2']), axis = 1)\n",
    "        plt.figure()\n",
    "        plt.imshow(pltImage, cmap='gray')\n",
    "        plt.title(f\"Class: {datapoint['label']} -- {self.classToStates[datapoint['label']]}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272796a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomTranslations(object):\n",
    "\n",
    "    def __init__(self, translate=(0.0, 0.10)):\n",
    "        self.translate = translate\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        #img_shape = sample['frame1'].shape[-2:]\n",
    "        #img_size = [img_shape[1], img_shape[0]]\n",
    "        affine_params = transforms.RandomAffine.get_params(degrees= [0,0], \n",
    "                                                           translate=self.translate,\n",
    "                                                           scale_ranges=None,\n",
    "                                                           shears=None,\n",
    "                                                           img_size=[36, 800])\n",
    "        #print(affine_params)\n",
    "        frame1Tensor = torch.from_numpy(sample['frame1']).unsqueeze(0)\n",
    "        frame2Tensor = torch.from_numpy(sample['frame2']).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        frame1Translated = transforms.functional.affine(frame1Tensor, *affine_params)\n",
    "        frame2Translated = transforms.functional.affine(frame2Tensor, *affine_params)\n",
    "        \n",
    "        sample['frame1'] = frame1Translated\n",
    "        sample['frame2'] = frame2Translated\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193d804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorizeSample(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        sample['frame1'] = torch.from_numpy(sample['frame1']).unsqueeze(0)\n",
    "        sample['frame2'] = torch.from_numpy(sample['frame2']).unsqueeze(0)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7913d8",
   "metadata": {},
   "source": [
    "phaseDirectoriesList = ['/home/pk/Documents/trainingData/deadalive1/' + str(i) + '/' for i in range(0, 41)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c37cb",
   "metadata": {},
   "source": [
    "dataset = statesDataset(phaseDirectoriesList, transforms = tensorizeSample())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8eecda",
   "metadata": {},
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59798b3",
   "metadata": {},
   "source": [
    "dataset.clasStatistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e81188",
   "metadata": {},
   "source": [
    "dataset[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bea899",
   "metadata": {},
   "source": [
    "dataset[0]['frame1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91c0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ed324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9181f5a3",
   "metadata": {},
   "source": [
    "### Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9215bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_relu_norm(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel=3, stride=1, padding=1):\n",
    "        super(conv_relu_norm, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=kernel, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channels, output_channels, kernel_size=kernel, stride=stride, padding=padding),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class stateNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses=6):\n",
    "        super(stateNet, self).__init__()\n",
    "        self.conv1 = conv_relu_norm(1, 64)\n",
    "        self.conv2 = conv_relu_norm(64, 128)\n",
    "        self.conv3 = conv_relu_norm(128, 256)\n",
    "        \n",
    "        self.conv4 = conv_relu_norm(256, 256)\n",
    "        \n",
    "        self.fc6 = nn.Linear(76800, 1024)\n",
    "        self.imageFeatures = nn.Sequential(\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.outputLinear = nn.Sequential(\n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(256, nClasses)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward_one(self, img):\n",
    "        # get to conv feature head for each image\n",
    "        \n",
    "        #print(f\"Image shape: {img.shape}\")\n",
    "        batch_size = img.shape[0]\n",
    "        \n",
    "        conv1 = self.conv1(img)\n",
    "        #print(f\"Conv1 shape: {conv1.shape}\")\n",
    "        pool1 = F.relu(F.max_pool2d(conv1, (2, 2)))\n",
    "        #print(f\"Pool1 shape: {pool1.shape}\")\n",
    "        \n",
    "        conv2 = self.conv2(pool1)\n",
    "        #print(f\"Conv2 shape: {conv2.shape}\")\n",
    "        pool2 = F.relu(F.max_pool2d(conv2, (2, 2)))\n",
    "        #print(f\"Pool2 shape: {pool2.shape}\")\n",
    "        \n",
    "        conv3 = self.conv3(pool2)\n",
    "        #print(f\"Conv3 shape: {conv3.shape}\")\n",
    "        pool3 = F.relu(F.max_pool2d(conv3, (2, 3)))\n",
    "        #print(f\"Pool3 shape: {pool3.shape}\")\n",
    "        \n",
    "        conv4 = self.conv4(pool3)\n",
    "        #print(f\"Conv4 shape: {conv4.shape}\")\n",
    "        conv4_reshaped = conv4.view(batch_size, -1)\n",
    "        #print(f\"Conv4 reshaped: {conv4_reshaped.shape}\")\n",
    "        \n",
    "        fc6 = F.relu(self.fc6(conv4_reshaped))\n",
    "        #print(f\"FC6 shape: {fc6.shape}\")\n",
    "        \n",
    "        out = self.imageFeatures(fc6)\n",
    "        #print(f\"Output shape: {out.shape}\")\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        # pass the sample image through the net seperately and then\n",
    "        \n",
    "        imgFeatures1 = self.forward_one(img1)\n",
    "        imgFeatures2 = self.forward_one(img2)\n",
    "        \n",
    "        # stack the image features\n",
    "        stackedFeatures = torch.cat((imgFeatures1, imgFeatures2), 1)\n",
    "        #print(stackedFeatures.shape)\n",
    "        \n",
    "        \n",
    "        netOutput = self.outputLinear(stackedFeatures)\n",
    "        #print(netOutput.shape)\n",
    "        \n",
    "        return netOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b6edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "664b970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phaseDirectoriesList = ['/home/pk/Documents/trainingData/deadalive1/' + str(i) + '/' for i in range(0, 41)]\n",
    "dataset = statesDataset(phaseDirectoriesList, transforms = randomTranslations())\n",
    "statedataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=6)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a84454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 355, 2: 162, 3: 919, 4: 53, 5: 71, 1: 38}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df29a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0028169 , 0.02631579, 0.00617284, 0.00108814, 0.01886792,\n",
       "       0.01408451])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf7b41",
   "metadata": {},
   "source": [
    "databatch = next(iter(stateDataLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "441c74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = stateNet(nClasses=6)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(dataset.weights,dtype=torch.float))\n",
    "criterion.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.00005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef232e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb7bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ..  ..Avg.Loss: 1.6113714838027955\n",
      "Epoch 2: ..  ..Avg.Loss: 1.3203878426551818\n",
      "Epoch 3: ..  ..Avg.Loss: 1.2294101679325105\n",
      "Epoch 4: ..  ..Avg.Loss: 1.0341612803936004\n",
      "Epoch 5: ..  ..Avg.Loss: 0.8394487237930298\n",
      "Epoch 6: ..  ..Avg.Loss: 0.7646921801567078\n",
      "Epoch 7: ..  ..Avg.Loss: 0.7429525434970856\n",
      "Epoch 8: ..  ..Avg.Loss: 0.6822455018758774\n",
      "Epoch 9: ..  ..Avg.Loss: 0.6473642086982727\n",
      "Epoch 10: ..  ..Avg.Loss: 0.6441334372758866\n",
      "Epoch 11: ..  ..Avg.Loss: 0.5443035015463829\n",
      "Epoch 12: ..  ..Avg.Loss: 0.564657284617424\n",
      "Epoch 13: ..  ..Avg.Loss: 0.5176343956589698\n",
      "Epoch 14: ..  ..Avg.Loss: 0.5106999018788337\n",
      "Epoch 15: ..  ..Avg.Loss: 0.4393028458952904\n",
      "Epoch 16: ..  ..Avg.Loss: 0.40086173951625825\n",
      "Epoch 17: ..  ..Avg.Loss: 0.375201066583395\n",
      "Epoch 18: ..  ..Avg.Loss: 0.4025968986749649\n",
      "Epoch 19: ..  ..Avg.Loss: 0.36361352652311324\n",
      "Epoch 20: ..  ..Avg.Loss: 0.5315257807075977\n",
      "Epoch 21: ..  ..Avg.Loss: 0.3563631580770016\n",
      "Epoch 22: ..  ..Avg.Loss: 0.27450292721390723\n",
      "Epoch 23: ..  ..Avg.Loss: 0.31211841851472855\n",
      "Epoch 24: ..  ..Avg.Loss: 0.306992853730917\n",
      "Epoch 25: ..  ..Avg.Loss: 0.27051688097417353\n",
      "Epoch 26: ..  ..Avg.Loss: 0.2580011057853699\n",
      "Epoch 27: ..  ..Avg.Loss: 0.2381666574627161\n",
      "Epoch 28: ..  ..Avg.Loss: 0.213523271381855\n",
      "Epoch 29: ..  ..Avg.Loss: 0.24881860136985778\n",
      "Epoch 30: ..  ..Avg.Loss: 0.24066754173487426\n",
      "Epoch 31: ..  ..Avg.Loss: 0.20229610435664655\n",
      "Epoch 32: ..  ..Avg.Loss: 0.23974004458636045\n",
      "Epoch 33: ..  ..Avg.Loss: 0.20724795661866666\n",
      "Epoch 34: ..  ..Avg.Loss: 0.18904139570891856\n",
      "Epoch 35: ..  ..Avg.Loss: 0.16150694392621517\n",
      "Epoch 36: ..  ..Avg.Loss: 0.2163774912804365\n",
      "Epoch 37: ..  ..Avg.Loss: 0.18437671296298505\n",
      "Epoch 38: ..  ..Avg.Loss: 0.15796567857265473\n",
      "Epoch 39: ..  ..Avg.Loss: 0.14588187474757433\n",
      "Epoch 40: ..  ..Avg.Loss: 0.1455998856946826\n",
      "Epoch 41: ..  ..Avg.Loss: 0.13742890698835253\n",
      "Epoch 42: ..  ..Avg.Loss: 0.10127031251788139\n",
      "Epoch 43: ..  ..Avg.Loss: 0.10691800510510802\n",
      "Epoch 44: ..  ..Avg.Loss: 0.098464724868536\n",
      "Epoch 45: ..  ..Avg.Loss: 0.08362609541043639\n",
      "Epoch 46: ..  ..Avg.Loss: 0.0875573612190783\n",
      "Epoch 47: ..  ..Avg.Loss: 0.10251053374260664\n",
      "Epoch 48: ..  ..Avg.Loss: 0.0912280923873186\n",
      "Epoch 49: ..  ..Avg.Loss: 0.07341851575300097\n",
      "Epoch 50: ..  ..Avg.Loss: 0.07212704718112946\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 50\n",
    "for epoch in range(nEpochs):\n",
    "    epoch_loss = []\n",
    "    for i_batch, data_batch in enumerate(statedataloader, 0):\n",
    "        frame1_batch, frame2_batch, labels = data_batch['frame1'].to(device), data_batch['frame2'].to(device), data_batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_scores = net(frame1_batch, frame2_batch)\n",
    "        loss = criterion(output_scores, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}: ..  ..Avg.Loss: {np.mean(epoch_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "148b9435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9984e+01, -3.4243e+00,  7.8116e+00,  8.1063e+00, -3.3214e+00,\n",
       "          2.5880e+01],\n",
       "        [ 1.6100e+00, -6.4979e-01,  8.3550e+00,  1.1074e+01,  3.9870e+00,\n",
       "         -1.1433e+01],\n",
       "        [ 1.9542e+01, -2.3853e+00,  4.4177e+00,  4.7521e+00, -1.0958e+01,\n",
       "         -1.4001e+01],\n",
       "        [-9.7581e+00, -2.1334e+00, -4.4150e+00,  4.1795e+00,  4.0654e+00,\n",
       "          1.8854e+01],\n",
       "        [-3.6247e-01, -5.1557e+00,  4.5424e+00,  1.2419e+01,  6.0522e+00,\n",
       "         -7.1764e+00],\n",
       "        [-1.9390e+00, -4.5795e+00,  3.1794e+00,  1.3521e+01,  8.6621e+00,\n",
       "         -6.0092e+00],\n",
       "        [-8.9870e+00, -1.9495e+00, -4.7082e+00,  3.7203e+00,  2.3232e+00,\n",
       "          1.8959e+01],\n",
       "        [-2.9335e+00, -6.2057e+00,  3.0536e+00,  1.5225e+01,  1.0815e+01,\n",
       "         -6.6388e+00],\n",
       "        [ 1.3132e+00, -4.0695e+00,  5.4477e+00,  1.0198e+01,  3.2176e+00,\n",
       "         -7.2507e+00],\n",
       "        [ 5.4874e+00, -5.1591e+00,  9.3623e+00,  1.3886e+01,  8.2699e-01,\n",
       "         -1.2124e+01],\n",
       "        [ 7.9923e+00,  7.2648e+00,  8.9995e+00,  3.5907e+00, -5.6492e+00,\n",
       "         -1.4713e+01],\n",
       "        [ 2.7704e+00, -8.9660e-01, -3.5507e+00,  1.2689e+01,  3.5540e+00,\n",
       "         -5.1199e+00],\n",
       "        [ 1.8203e+01, -1.6939e-02,  7.6784e+00,  3.6720e+00, -1.0890e+01,\n",
       "         -1.5426e+01],\n",
       "        [ 5.3562e+00,  6.3888e+00,  2.8743e+00,  2.4276e+00, -7.3856e+00,\n",
       "         -7.4899e+00],\n",
       "        [ 3.4107e+00,  1.3119e+00,  5.2325e+00,  8.4337e+00,  3.6646e-01,\n",
       "         -8.9618e+00],\n",
       "        [ 5.5256e+00, -2.5805e+00,  1.0802e+01,  1.3445e+01,  3.9906e-01,\n",
       "         -1.2885e+01],\n",
       "        [ 8.3462e+00,  1.0405e+00,  1.0457e+01,  3.0150e+00, -5.0142e+00,\n",
       "         -9.9181e+00],\n",
       "        [-2.9921e+00, -5.2227e+00,  4.7483e+00,  1.4285e+01,  8.2192e+00,\n",
       "         -4.4402e+00],\n",
       "        [ 2.0844e+01,  4.1384e+00,  4.3154e+00,  2.3444e+00, -1.4357e+01,\n",
       "         -1.8375e+01],\n",
       "        [-1.2219e+00,  1.4709e+00,  5.7460e+00,  1.0051e+01, -3.7581e+00,\n",
       "         -3.7743e+00],\n",
       "        [ 6.3231e+00, -7.6842e+00,  9.7352e+00,  1.9900e+01,  1.7108e+00,\n",
       "         -1.5404e+01],\n",
       "        [-6.3455e+00, -2.3527e+00,  1.0186e-01,  6.7565e+00,  1.1562e+01,\n",
       "          9.9034e-01],\n",
       "        [ 1.1529e-01, -5.5969e+00,  4.1148e+00,  1.5600e+01,  6.4691e+00,\n",
       "         -7.5737e+00],\n",
       "        [ 2.1798e+00, -8.0722e+00,  4.8013e+00,  2.2647e+01,  7.0706e+00,\n",
       "         -1.3553e+01],\n",
       "        [ 1.2668e+00, -1.6079e+00,  8.9317e+00,  1.0700e+01,  1.9093e+00,\n",
       "         -9.3117e+00],\n",
       "        [ 4.8253e+00, -6.5128e+00,  7.7464e+00,  1.5358e+01,  1.8773e+00,\n",
       "         -1.2047e+01],\n",
       "        [ 1.9472e+01,  1.4379e+00,  1.1555e+01,  6.1485e+00, -1.3303e+01,\n",
       "         -1.8232e+01],\n",
       "        [ 9.0806e+00, -1.6437e+00,  1.0914e+01,  1.3842e+01, -2.5909e+00,\n",
       "         -1.7321e+01],\n",
       "        [ 1.2042e+00, -5.7546e+00,  5.1403e+00,  1.3905e+01,  5.2672e+00,\n",
       "         -8.5984e+00],\n",
       "        [ 1.8591e+01, -1.2669e+00,  5.5495e+00,  4.0453e+00, -1.1112e+01,\n",
       "         -1.4070e+01]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee2cabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "squish = nn.Softmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f91c4391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2067e-20, 1.8763e-13, 1.4223e-08, 1.9097e-08, 2.0796e-13, 1.0000e+00],\n",
       "        [7.2729e-05, 7.5913e-06, 6.1808e-02, 9.3733e-01, 7.8352e-04, 1.5750e-10],\n",
       "        [1.0000e+00, 3.0005e-10, 2.7021e-07, 3.7750e-07, 5.6768e-14, 2.7066e-15],\n",
       "        [3.7499e-13, 7.6800e-10, 7.8427e-11, 4.2369e-07, 3.7798e-07, 1.0000e+00],\n",
       "        [2.8059e-06, 2.3249e-08, 3.7865e-04, 9.9790e-01, 1.7136e-03, 3.0818e-09],\n",
       "        [1.9160e-07, 1.3667e-08, 3.2010e-05, 9.9227e-01, 7.6981e-03, 3.2714e-09],\n",
       "        [7.3003e-13, 8.3114e-10, 5.2671e-11, 2.4102e-07, 5.9607e-08, 1.0000e+00],\n",
       "        [1.2841e-08, 4.8696e-10, 5.1137e-06, 9.8799e-01, 1.2007e-02, 3.1579e-10],\n",
       "        [1.3709e-04, 6.2997e-07, 8.5621e-03, 9.9038e-01, 9.2057e-04, 2.6166e-08],\n",
       "        [2.2278e-04, 5.2984e-09, 1.0733e-02, 9.8904e-01, 2.1081e-06, 5.0036e-12],\n",
       "        [2.3622e-01, 1.1412e-01, 6.4676e-01, 2.8958e-03, 2.8114e-07, 3.2550e-11],\n",
       "        [4.9249e-05, 1.2584e-06, 8.8542e-08, 9.9984e-01, 1.0782e-04, 1.8436e-08],\n",
       "        [9.9997e-01, 1.2223e-08, 2.6868e-05, 4.8895e-07, 2.3168e-13, 2.4836e-15],\n",
       "        [2.5344e-01, 7.1182e-01, 2.1185e-02, 1.3553e-02, 7.4167e-07, 6.6821e-07],\n",
       "        [6.2806e-03, 7.7002e-04, 3.8832e-02, 9.5382e-01, 2.9916e-04, 2.6587e-08],\n",
       "        [3.3933e-04, 1.0238e-07, 6.6373e-02, 9.3329e-01, 2.0146e-06, 3.4287e-12],\n",
       "        [1.0796e-01, 7.2522e-05, 8.9144e-01, 5.2238e-04, 1.7019e-07, 1.2624e-09],\n",
       "        [3.1304e-08, 3.3641e-09, 7.1981e-05, 9.9761e-01, 2.3152e-03, 7.3564e-09],\n",
       "        [1.0000e+00, 5.5598e-08, 6.6360e-08, 9.2455e-09, 5.1579e-16, 9.2822e-18],\n",
       "        [1.2540e-05, 1.8525e-04, 1.3317e-02, 9.8648e-01, 9.9272e-07, 9.7676e-07],\n",
       "        [1.2696e-06, 1.0480e-12, 3.8504e-05, 9.9996e-01, 1.2606e-08, 4.6506e-16],\n",
       "        [1.6564e-08, 8.9789e-07, 1.0452e-05, 8.1151e-03, 9.9185e-01, 2.5414e-05],\n",
       "        [1.8829e-07, 6.2238e-10, 1.0275e-05, 9.9988e-01, 1.0820e-04, 8.6207e-11],\n",
       "        [1.2916e-09, 4.5574e-14, 1.7767e-08, 1.0000e+00, 1.7185e-07, 1.8987e-16],\n",
       "        [6.8328e-05, 3.8560e-06, 1.4570e-01, 8.5410e-01, 1.2991e-04, 1.7394e-09],\n",
       "        [2.6638e-05, 3.1723e-10, 4.9442e-04, 9.9948e-01, 1.3969e-06, 1.2528e-12],\n",
       "        [9.9963e-01, 1.4715e-08, 3.6422e-04, 1.6351e-06, 5.8310e-15, 4.2170e-17],\n",
       "        [8.0534e-03, 1.7720e-07, 5.0375e-02, 9.4157e-01, 6.8724e-08, 2.7540e-14],\n",
       "        [3.0492e-06, 2.8974e-09, 1.5617e-04, 9.9966e-01, 1.7730e-04, 1.6865e-10],\n",
       "        [1.0000e+00, 2.3769e-09, 2.1693e-06, 4.8201e-07, 1.2596e-13, 6.5399e-15]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squish(output_scores.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a63952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b833e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel = {\n",
    "    'model_state_dict': net.state_dict(),\n",
    "    'labels': class_to_states\n",
    "}\n",
    "torch.save(savedModel, '/home/pk/Documents/models/multistate.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a9429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ef48828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77b444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445967d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fcba6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = []\n",
    "predicted_labels = []\n",
    "squish = nn.Softmax(dim = 1)\n",
    "with torch.no_grad():\n",
    "    for i_batch, data_batch in enumerate(statedataloader, 0):\n",
    "        frame1_batch, frame2_batch, labels = data_batch['frame1'].to(device), data_batch['frame2'].to(device), data_batch['label'].to(device)\n",
    "        \n",
    "        output_scores = net(frame1_batch, frame2_batch)\n",
    "        output_scoresCPU = output_scores.cpu()\n",
    "        output_labels = squish(output_scoresCPU).numpy().argmax(axis = 1)\n",
    "        labels_cpu = labels.cpu().numpy()\n",
    "        \n",
    "        actual_labels.extend(list(labels_cpu))\n",
    "        predicted_labels.extend(list(output_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caa72e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9841d82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51e30342",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(actual_labels, predicted_labels, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4123aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "ax.set_title('Classification errors')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "#ax.set_xticklabels([''] + labels)\n",
    "#ax.set_yticklabels([''] + labels)\n",
    "for (i, j), z in np.ndenumerate(cm):\n",
    "    ax.text(j, i, z, ha='center', va='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b4831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e5d210b",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c45cfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testData(object):\n",
    "    \n",
    "    def __init__(self, phaseDir, fileformat='.tiff'):\n",
    "        \n",
    "        self.phaseDir = phaseDir\n",
    "        self.fileformat = fileformat\n",
    "        self.indices = [int(filename.split('.')[0].split('/')[-1]) for filename in \n",
    "                       glob.glob(self.phaseDir + \"*\" + self.fileformat)]\n",
    "        self.indices.sort()\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.indices) - 1\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        phaseFilename1 = self.phaseDir + str(self.indices[idx]) + self.fileformat\n",
    "        phaseFilename2 = self.phaseDir + str(self.indices[idx+1]) + self.fileformat\n",
    "        img1 = io.imread(phaseFilename1)\n",
    "        img2 = io.imread(phaseFilename2)\n",
    "        #print(phaseFilename1)\n",
    "        #print(phaseFilename2)\n",
    "        \n",
    "        return {\n",
    "            'frame1': torch.from_numpy(img1).unsqueeze(0).unsqueeze(0),\n",
    "            'frame2': torch.from_numpy(img2).unsqueeze(0).unsqueeze(0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfee3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "phaseTestDir = '/home/pk/Documents/trainingData/deadalive1/89/'\n",
    "testdata = testData(phaseTestDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49827cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stateNet(\n",
       "  (conv1): conv_relu_norm(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): conv_relu_norm(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): conv_relu_norm(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv4): conv_relu_norm(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (fc6): Linear(in_features=76800, out_features=1024, bias=True)\n",
       "  (imageFeatures): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (outputLinear): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = stateNet()\n",
    "savedNet = torch.load('/home/pk/Documents/models/multistate.pth')\n",
    "net.load_state_dict(savedNet['model_state_dict'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c835c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] -- [[0.99 0.   0.   0.   0.   0.  ]]\n",
      "[0] -- [[1. 0. 0. 0. 0. 0.]]\n",
      "[0] -- [[1. 0. 0. 0. 0. 0.]]\n",
      "[0] -- [[1. 0. 0. 0. 0. 0.]]\n",
      "[0] -- [[1. 0. 0. 0. 0. 0.]]\n",
      "[0] -- [[0.97 0.03 0.   0.   0.   0.  ]]\n",
      "[0] -- [[0.75 0.24 0.   0.   0.   0.  ]]\n",
      "[1] -- [[0. 1. 0. 0. 0. 0.]]\n",
      "[1] -- [[0.01 0.99 0.   0.   0.   0.  ]]\n",
      "[0] -- [[0.93 0.06 0.   0.   0.   0.  ]]\n",
      "[1] -- [[0.04 0.96 0.01 0.   0.   0.  ]]\n",
      "[1] -- [[0.1 0.9 0.  0.  0.  0. ]]\n",
      "[1] -- [[0.09 0.9  0.01 0.   0.   0.  ]]\n",
      "[1] -- [[0.02 0.98 0.01 0.   0.   0.  ]]\n",
      "[1] -- [[0.25 0.73 0.01 0.   0.   0.  ]]\n",
      "[1] -- [[0.05 0.94 0.01 0.   0.   0.  ]]\n",
      "[0] -- [[0.51 0.44 0.04 0.   0.   0.  ]]\n",
      "[1] -- [[0.23 0.72 0.05 0.   0.   0.  ]]\n",
      "[1] -- [[0.   0.99 0.01 0.   0.   0.  ]]\n",
      "[1] -- [[0. 1. 0. 0. 0. 0.]]\n",
      "[0] -- [[0.84 0.09 0.07 0.   0.   0.  ]]\n",
      "[2] -- [[0.1  0.31 0.59 0.01 0.   0.  ]]\n",
      "[0] -- [[0.88 0.07 0.05 0.   0.   0.  ]]\n",
      "[1] -- [[0.   0.99 0.01 0.   0.   0.  ]]\n",
      "[1] -- [[0.15 0.77 0.08 0.   0.   0.  ]]\n",
      "[1] -- [[0.09 0.86 0.05 0.   0.   0.  ]]\n",
      "[1] -- [[0.23 0.71 0.06 0.   0.   0.  ]]\n",
      "[1] -- [[0. 1. 0. 0. 0. 0.]]\n",
      "[1] -- [[0.   0.98 0.02 0.   0.   0.  ]]\n",
      "[1] -- [[0.16 0.66 0.18 0.   0.   0.  ]]\n",
      "[1] -- [[0.11 0.81 0.08 0.   0.   0.  ]]\n",
      "[1] -- [[0.03 0.93 0.04 0.   0.   0.  ]]\n",
      "[1] -- [[0.03 0.89 0.09 0.   0.   0.  ]]\n",
      "[0] -- [[0.57 0.37 0.05 0.   0.   0.  ]]\n",
      "[1] -- [[0.01 0.86 0.14 0.   0.   0.  ]]\n",
      "[1] -- [[0.27 0.61 0.12 0.   0.   0.  ]]\n",
      "[1] -- [[0.04 0.85 0.11 0.   0.   0.  ]]\n",
      "[1] -- [[0.05 0.87 0.07 0.   0.   0.  ]]\n",
      "[1] -- [[0.03 0.8  0.18 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "squish = nn.Softmax(dim = 1)\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "for i in range(39):\n",
    "    out = net(testdata[i]['frame1'], testdata[i]['frame2'])\n",
    "    print(f\"{squish(out).detach().numpy().argmax(axis =1)} -- {squish(out).detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7e1324d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.8738,  7.3161,  5.8150, -1.6393, -5.4459, -8.2013]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac9ea383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7514e-02, 1.0395e-02, 9.5118e-01, 8.9237e-04, 1.5333e-05, 2.5778e-08]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squish = nn.Softmax(dim = 1)\n",
    "squish(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea4837",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testPlot(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self):\n",
    "        pass\n",
    "    \n",
    "    def getStateChange(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd555811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f0503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNet(dataDir, modelPath, fileformat='.tiff', plot=False):\n",
    "        \n",
    "    # net intializee and run\n",
    "    net = ()\n",
    "    saved_net_parameters = torch.load(modelPath)\n",
    "    net.load_state_dict(saved_net_parameters['model_state_dict'])\n",
    "    net.eval()\n",
    "    \n",
    "    filenames = [int(filename.split('.')[0].split('/')[-1]) \n",
    "             for filename in glob.glob(dataDir + \"*\"+ fileformat)]\n",
    "    filenames.sort()\n",
    "    sortedFilenames = [dataDir + str(filenumber) + fileformat for filenumber in filenames]\n",
    "    print(sortedFilenames)\n",
    "    \n",
    "    imgTransforms = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    predicted_states =[]\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sortedFilenames) - 1):\n",
    "            img1 = io.imread(sortedFilenames[i])\n",
    "            img2 = io.imread(sortedFilenames[i+1])\n",
    "            \n",
    "            img1 = imgTransforms(img1).unsqueeze(0)\n",
    "            img2 = imgTransforms(img2).unsqueeze(0)\n",
    "            output = net(img1, img2) > 0.5\n",
    "            print(output.item())\n",
    "            predicted_states.append(output.item())\n",
    "            \n",
    "    \n",
    "    \n",
    "    if plot == True:\n",
    "        states = np.array(predicted_states).T\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "        img = io.imread(sortedFilenames[0])\n",
    "\n",
    "        tdata, movingdata, = [], []\n",
    "        movingplot, = ax[1].plot([], [], 'g,:', label='Moving')\n",
    "        #partialdeadplot, = ax[1].plot([], [], 'r,-.', label='Partial Dead')\n",
    "        #alldeadplot, = ax[1].plot([], [], 'k--', label='All Dead')\n",
    "        #nocellsplot, = ax[1].plot([], [], 'b*', label='No cells')\n",
    "        #cellsvanishplot, = ax[1].plot([], [], 'mo', label='Cells vanish')\n",
    "\n",
    "\n",
    "        imgplot = ax[0].imshow(img, cmap='gray')\n",
    "\n",
    "\n",
    "        def init():\n",
    "            img = io.imread(sortedFilenames[0])\n",
    "            imgplot.set_array(img)\n",
    "            ax[1].set_xlim([0, len(sortedFilenames)])\n",
    "            ax[1].set_ylim([-0.5, 2])\n",
    "            return imgplot, \n",
    "\n",
    "        def update(frame):\n",
    "\n",
    "            img = io.imread(sortedFilenames[frame])\n",
    "            imgplot.set_array(img)\n",
    "            tdata.append(frame)\n",
    "            movingdata.append(int(states[0][frame]))\n",
    "            movingplot.set_data(tdata, movingdata) \n",
    "\n",
    "            partialdeaddata.append(int(states[2][frame]))\n",
    "            partialdeadplot.set_data(tdata, partialdeaddata)\n",
    "\n",
    "            alldeaddata.append(int(states[3][frame]))\n",
    "            alldeadplot.set_data(tdata, alldeaddata)\n",
    "\n",
    "            nocellsdata.append(int(states[4][frame]))\n",
    "            nocellsplot.set_data(tdata, nocellsdata)\n",
    "\n",
    "            cellsvanishdata.append(int(states[5][frame]))\n",
    "            cellsvanishplot.set_data(tdata, cellsvanishdata)\n",
    "\n",
    "\n",
    "            return [imgplot, movingplot, partialdeadplot,]\n",
    "\n",
    "        ani = FuncAnimation(fig, update, frames=range(0, len(sortedFilenames)),\n",
    "                            init_func=init, blit=False, repeat=False, interval=1000)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "        \n",
    "    return None, predicted_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3170fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccf8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09b6036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_states = {\n",
    "    0: 'all_growing',\n",
    "    1: 'partly_growing',\n",
    "    2: 'stopped_growing',\n",
    "    3: 'stopped_fading',\n",
    "    4: 'stopped_vanishing',\n",
    "    5: 'channel_empty'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7217dd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_growing\n",
      "partly_growing\n",
      "stopped_growing\n",
      "stopped_fading\n",
      "stopped_vanishing\n",
      "channel_empty\n"
     ]
    }
   ],
   "source": [
    "for key in class_to_states:\n",
    "    print(class_to_states[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "427696b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in class_to_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e0001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab02219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_to_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de07d3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'0_1'.split(\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63d04b",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd97c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2efcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6503eea6",
   "metadata": {},
   "source": [
    "### Test plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04256220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
