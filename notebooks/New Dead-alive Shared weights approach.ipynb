{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7259b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button, CheckButtons, RadioButtons\n",
    "import pickle\n",
    "from skimage import io\n",
    "import glob\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963fc93",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be91abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class markStateTransition(object):\n",
    "    \n",
    "    def __init__(self, phaseDir=None, fileformat='.tiff', saveFilename='states.pickle'):\n",
    "        self.phaseDir = phaseDir\n",
    "        self.fileformat = fileformat\n",
    "        self.saveFilename = saveFilename\n",
    "        self.indices = [int(filename.split('.')[0].split('/')[-1]) for filename in \n",
    "                       glob.glob(self.phaseDir + \"*\" + self.fileformat)]\n",
    "        self.indices.sort()\n",
    "        self.states = {}  # it is a dictionary\n",
    "        # with keys as directory name, file index 1, file index 2 and states\n",
    "        self.states['dirName'] = phaseDir\n",
    "        self.states['data'] = [] # use keys frame1, frame2 and keys for each of the state\n",
    "        \n",
    "        \n",
    "        self.fig, (self.ax1, self.ax2) = plt.subplots(1, 2, num=str(self.phaseDir))\n",
    "        plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "        self.axcolor = 'lightgoldenrodyellow'\n",
    "        \n",
    "        #\n",
    "        self.frame1 = 0\n",
    "        self.pltFrame1 = self.ax1.imshow(self.__getitem__(self.frame1), cmap='gray')\n",
    "        self.ax1.set_title(str(self.frame1) + self.fileformat)\n",
    "        self.frame2 = 1\n",
    "        self.pltFrame2 = self.ax2.imshow(self.__getitem__(self.frame2), cmap='gray')\n",
    "        self.ax2.set_title(str(self.frame2) + self.fileformat)\n",
    "        \n",
    "        # buttons\n",
    "        # next and save\n",
    "        self.previousax = plt.axes([0.5, 0.025, 0.1, 0.03])\n",
    "        self.nextax = plt.axes([0.65, 0.025, 0.1, 0.03])\n",
    "        self.saveax = plt.axes([0.8, 0.025, 0.1, 0.03])\n",
    "        self.nextButton = Button(self.nextax, 'Next', color=self.axcolor, hovercolor='0.975')\n",
    "        self.saveButton = Button(self.saveax, 'Save', color=self.axcolor, hovercolor='0.975')\n",
    "        self.previousButton = Button(self.previousax, 'Previous', color=self.axcolor, hovercolor='0.975')\n",
    "        self.nextButton.on_clicked(self.nextImage)\n",
    "        self.previousButton.on_clicked(self.previousImage)\n",
    "        self.saveButton.on_clicked(self.save)\n",
    "        \n",
    "        # Radio buttons for each category transition\n",
    "        \n",
    "        self.rax = plt.axes([0.05, 0.7, 0.15, 0.15], facecolor=self.axcolor)\n",
    "        self.radio = RadioButtons(self.rax, ('moved', 'not moved'))\n",
    "        self.moved = True\n",
    "        self.radio.on_clicked(self.changeMovedState)\n",
    "        \n",
    "        \n",
    "        # more radiobuttons for other states\n",
    "        \n",
    "        \n",
    "        self.reachedEnd = False\n",
    "        \n",
    "        \n",
    "        plt.pause(0.01)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.__len__():\n",
    "            phaseFilename = self.phaseDir + str(self.indices[idx]) + self.fileformat\n",
    "            #print(phaseFilename)\n",
    "            return io.imread(phaseFilename)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def changeMovedState(self, label):\n",
    "        moved_dict = {'moved': True, 'not moved': False}\n",
    "        self.moved = moved_dict[label]\n",
    "    \n",
    "    def nextImage(self, buttonPress):\n",
    "        # store the current state in the data\n",
    "        if self.frame2 <= len(self.indices) - 1 and self.reachedEnd == False:\n",
    "            self.states['data'].append({\n",
    "                'frame1': self.phaseDir + str(self.frame1) + self.fileformat,\n",
    "                'frame2': self.phaseDir + str(self.frame2) + self.fileformat,\n",
    "                'moved': self.moved\n",
    "                })\n",
    "            print(self.states['data'][-1])\n",
    "            \n",
    "            if self.frame2 == len(self.indices) - 1:\n",
    "                self.reachedEnd = True\n",
    "                print('Last frame reached')\n",
    "                return\n",
    "            \n",
    "            \n",
    "            if self.frame2 < len(self.indices) - 1:\n",
    "                self.frame1 += 1\n",
    "                self.frame2 += 1\n",
    "                self.pltFrame1.set_data(self.__getitem__(self.frame1))\n",
    "                self.ax1.set_title(str(self.frame1) + self.fileformat)\n",
    "                self.pltFrame2.set_data(self.__getitem__(self.frame2))\n",
    "                self.ax2.set_title(str(self.frame2) + self.fileformat)\n",
    "                self.fig.canvas.draw()\n",
    "            \n",
    "            \n",
    "    def previousImage(self, buttonPress):\n",
    "        \n",
    "        if self.frame1 == 0:\n",
    "            print('First frame reached')\n",
    "            return\n",
    "        else:\n",
    "            if len(self.states['data']) != 0:\n",
    "                del self.states['data'][-1]\n",
    "            \n",
    "            self.reachedEnd = False\n",
    "                \n",
    "            self.frame1 -= 1\n",
    "            self.frame2 -= 1\n",
    "            self.pltFrame1.set_data(self.__getitem__(self.frame1))\n",
    "            self.ax1.set_title(str(self.frame1) + self.fileformat)\n",
    "            self.pltFrame2.set_data(self.__getitem__(self.frame2))\n",
    "            self.ax2.set_title(str(self.frame2) + self.fileformat)\n",
    "            self.fig.canvas.draw()\n",
    "    \n",
    "    def save(self, save):\n",
    "        print(self.states)\n",
    "        saveFilename = self.phaseDir + self.saveFilename\n",
    "        with open(saveFilename, 'wb') as f:\n",
    "            pickle.dump(self.states, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"File saved {saveFilename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb5bbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/0.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/1.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/1.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/2.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/2.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/3.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/3.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/4.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/4.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/5.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/5.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/6.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/6.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/7.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/7.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/6.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/7.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/7.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/7.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/9.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/9.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/9.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/9.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/10.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/10.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/11.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/11.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/12.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/12.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/13.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/13.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/14.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/14.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/15.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/15.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/16.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/16.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/17.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/17.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/18.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/18.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/19.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/19.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/20.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/17.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/18.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/18.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/19.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/19.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/20.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/20.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/21.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/21.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/22.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/22.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/23.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/23.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/25.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/23.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/25.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/25.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/26.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/26.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/27.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/27.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/28.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/23.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'moved': True}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/25.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/25.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/26.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/26.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/27.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/27.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/28.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/28.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/29.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/29.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/30.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/30.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/31.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/31.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/32.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/32.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/33.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/33.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/34.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/34.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/35.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/35.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/36.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/36.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/37.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/37.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/38.tiff', 'moved': False}\n",
      "{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/38.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/39.tiff', 'moved': False}\n",
      "Last frame reached\n",
      "{'dirName': '/home/pk/Documents/trainingData/deadalive1/18/', 'data': [{'frame1': '/home/pk/Documents/trainingData/deadalive1/18/0.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/1.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/1.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/2.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/2.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/3.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/3.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/4.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/4.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/5.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/5.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/6.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/6.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/7.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/7.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/8.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/9.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/9.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/10.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/10.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/11.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/11.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/12.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/12.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/13.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/13.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/14.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/14.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/15.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/15.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/16.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/16.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/17.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/17.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/18.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/18.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/19.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/19.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/20.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/20.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/21.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/21.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/22.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/22.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/23.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/23.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'moved': True}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/24.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/25.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/25.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/26.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/26.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/27.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/27.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/28.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/28.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/29.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/29.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/30.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/30.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/31.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/31.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/32.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/32.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/33.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/33.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/34.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/34.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/35.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/35.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/36.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/36.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/37.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/37.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/38.tiff', 'moved': False}, {'frame1': '/home/pk/Documents/trainingData/deadalive1/18/38.tiff', 'frame2': '/home/pk/Documents/trainingData/deadalive1/18/39.tiff', 'moved': False}]}\n",
      "File saved /home/pk/Documents/trainingData/deadalive1/18/states.pickle\n"
     ]
    }
   ],
   "source": [
    "phaseDir = '/home/pk/Documents/trainingData/deadalive1/19/'\n",
    "genData = markStateTransition(phaseDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ac3db",
   "metadata": {},
   "source": [
    "### Data loader and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8757a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cellsMovingDataset(object):\n",
    "    \n",
    "    def __init__(self, phaseDirectoriesList, fileformat='.tiff',transforms=None):\n",
    "        \n",
    "        self.phaseDirectoriesList = phaseDirectoriesList\n",
    "        self.data = []\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        for directory in self.phaseDirectoriesList:\n",
    "            # read the states file\n",
    "            statesFilename = directory + 'states.pickle'\n",
    "            with open(statesFilename, 'rb') as file:\n",
    "                states = pickle.load(file)\n",
    "            data = states['data']\n",
    "            \n",
    "            self.data.extend(data)\n",
    "    \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        datapoint = self.data[idx]\n",
    "        \n",
    "        frame1 = io.imread(datapoint['frame1'])\n",
    "        frame2 = io.imread(datapoint['frame2'])\n",
    "        cellsmoving = datapoint['moved']\n",
    "        \n",
    "        sample ={\n",
    "            'frame1': frame1,\n",
    "            'frame2': frame2,\n",
    "            'cellsmoving': cellsmoving,\n",
    "            'frame1file': datapoint['frame1'],\n",
    "            'frame2file': datapoint['frame2']\n",
    "        }\n",
    "    \n",
    "        \n",
    "        if self.transforms != None:\n",
    "            sample = self.transforms(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def statistics(self):\n",
    "        stats = {'moved': 0, 'notmoved': 0}\n",
    "        for datapoint in self.data:\n",
    "            if datapoint['moved']:\n",
    "                stats['moved'] += 1\n",
    "            else:\n",
    "                stats['notmoved'] += 1\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def plotDatapoint(self, idx):\n",
    "        \n",
    "        datapoint = self.__getitem__(idx)       \n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        plt.title(datapoint['frame1file'].split('/')[0])\n",
    "        ax[0].imshow(datapoint['frame1'], cmap='gray')\n",
    "        ax[1].imshow(datapoint['frame2'], cmap='gray')\n",
    "        \n",
    "        ax[0].set_title(f\"Moved : {datapoint['cellsmoving']}\")\n",
    "        ax[1].set_title(f\"Moved: {datapoint['cellsmoving']}\")\n",
    "        plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a15722",
   "metadata": {},
   "source": [
    "### Data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837f5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomTranslations(object):\n",
    "\n",
    "    def __init__(self, translate=(0.0, 0.10)):\n",
    "        self.translate = translate\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        #img_shape = sample['frame1'].shape[-2:]\n",
    "        #img_size = [img_shape[1], img_shape[0]]\n",
    "        affine_params = transforms.RandomAffine.get_params(degrees= [0,0], \n",
    "                                                           translate=self.translate,\n",
    "                                                           scale_ranges=None,\n",
    "                                                           shears=None,\n",
    "                                                           img_size=[36, 800])\n",
    "        #print(affine_params)\n",
    "        frame1Tensor = torch.from_numpy(sample['frame1']).unsqueeze(0)\n",
    "        frame2Tensor = torch.from_numpy(sample['frame2']).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        frame1Translated = transforms.functional.affine(frame1Tensor, *affine_params)\n",
    "        frame2Translated = transforms.functional.affine(frame2Tensor, *affine_params)\n",
    "        \n",
    "        return {\n",
    "            'frame1': frame1Translated,\n",
    "            'frame2': frame2Translated,\n",
    "            'cellsmoving': torch.tensor(sample['cellsmoving'],dtype=torch.float).unsqueeze(0),\n",
    "            'frame1file': sample['frame1file'],\n",
    "            'frame2file': sample['frame2file']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e288f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomVerticalFlips(object):\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        self.probability = p\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        if random.random() < self.probability:\n",
    "            # then flip both images\n",
    "            sample['frame1'] = transforms.functional.vflip(sample['frame1'])\n",
    "            sample['frame2'] = transforms.functional.vflip(sample['frame2'])\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c201d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "phaseDirectoriesList = ['/home/pk/Documents/trainingData/deadalive1/0/',\n",
    "                        '/home/pk/Documents/trainingData/deadalive1/1/',\n",
    "                       '/home/pk/Documents/trainingData/deadalive1/2/',\n",
    "                       '/home/pk/Documents/trainingData/deadalive1/3/',\n",
    "                       '/home/pk/Documents/trainingData/deadalive1/4/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c115daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cellsMovingDataset(phaseDirectoriesList, transforms = randomTranslations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2facc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.plotDatapoint(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a675004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moved': 51, 'notmoved': 160}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd0770",
   "metadata": {},
   "source": [
    "datapoint = data[0]\n",
    "#t_sample = f(t_sample)\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "plt.title(datapoint['frame1file'].split('/')[0])\n",
    "ax[0].imshow(t_sample['frame1'].numpy().squeeze(0), cmap='gray')\n",
    "ax[1].imshow(datapoint['frame1'], cmap='gray')\n",
    "ax[2].imshow(t_sample['frame2'].numpy().squeeze(0), cmap='gray')\n",
    "ax[3].imshow(datapoint['frame2'], cmap='gray')\n",
    "\n",
    "ax[0].set_title(f\"Moved : {t_sample['cellsmoving']}\")\n",
    "ax[1].set_title(f\"Moved: {datapoint['cellsmoving']}\")\n",
    "ax[2].set_title(f\"Moved: {t_sample['cellsmoving']}\")\n",
    "ax[3].set_title(f\"Moved: {datapoint['cellsmoving']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5117b057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame1': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [-0.4336, -0.4748, -0.4768,  ..., -0.4591, -0.4061, -0.4375],\n",
       "          [-0.4571, -0.4512, -0.4395,  ..., -0.4709, -0.4061, -0.4512],\n",
       "          [-0.4316, -0.4257, -0.5042,  ..., -0.3923, -0.3923, -0.4355]]]),\n",
       " 'frame2': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [-0.4629, -0.4688, -0.4156,  ..., -0.4452, -0.4688, -0.4057],\n",
       "          [-0.4570, -0.4550, -0.4116,  ..., -0.4491, -0.4116, -0.4373],\n",
       "          [-0.3919, -0.3683, -0.4432,  ..., -0.4333, -0.4491, -0.4688]]]),\n",
       " 'cellsmoving': tensor([1.]),\n",
       " 'frame1file': '/home/pk/Documents/trainingData/deadalive1/0/0.tiff',\n",
       " 'frame2file': '/home/pk/Documents/trainingData/deadalive1/0/1.tiff'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc2f1b",
   "metadata": {},
   "source": [
    "### Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7265e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_relu_norm(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel=3, stride=1, padding=1):\n",
    "        super(conv_relu_norm, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=kernel, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channels, output_channels, kernel_size=kernel, stride=stride, padding=padding),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class movingNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(movingNet, self).__init__()\n",
    "        self.conv1 = conv_relu_norm(1, 64)\n",
    "        self.conv2 = conv_relu_norm(64, 128)\n",
    "        self.conv3 = conv_relu_norm(128, 256)\n",
    "        \n",
    "        self.conv4 = conv_relu_norm(256, 256)\n",
    "        \n",
    "        self.fc6 = nn.Linear(76800, 1024)\n",
    "        self.imageFeatures = nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.outputLinear = nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward_one(self, img):\n",
    "        # get to conv feature head for each image\n",
    "        \n",
    "        #print(f\"Image shape: {img.shape}\")\n",
    "        batch_size = img.shape[0]\n",
    "        \n",
    "        conv1 = self.conv1(img)\n",
    "        #print(f\"Conv1 shape: {conv1.shape}\")\n",
    "        pool1 = F.relu(F.max_pool2d(conv1, (2, 2)))\n",
    "        #print(f\"Pool1 shape: {pool1.shape}\")\n",
    "        \n",
    "        conv2 = self.conv2(pool1)\n",
    "        #print(f\"Conv2 shape: {conv2.shape}\")\n",
    "        pool2 = F.relu(F.max_pool2d(conv2, (2, 2)))\n",
    "        #print(f\"Pool2 shape: {pool2.shape}\")\n",
    "        \n",
    "        conv3 = self.conv3(pool2)\n",
    "        #print(f\"Conv3 shape: {conv3.shape}\")\n",
    "        pool3 = F.relu(F.max_pool2d(conv3, (2, 3)))\n",
    "        #print(f\"Pool3 shape: {pool3.shape}\")\n",
    "        \n",
    "        conv4 = self.conv4(pool3)\n",
    "        #print(f\"Conv4 shape: {conv4.shape}\")\n",
    "        conv4_reshaped = conv4.view(batch_size, -1)\n",
    "        #print(f\"Conv4 reshaped: {conv4_reshaped.shape}\")\n",
    "        \n",
    "        fc6 = F.relu(self.fc6(conv4_reshaped))\n",
    "        #print(f\"FC6 shape: {fc6.shape}\")\n",
    "        \n",
    "        out = self.imageFeatures(fc6)\n",
    "        #print(f\"Output shape: {out.shape}\")\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        # pass the sample image through the net seperately and then\n",
    "        \n",
    "        imgFeatures1 = self.forward_one(img1)\n",
    "        imgFeatures2 = self.forward_one(img2)\n",
    "        \n",
    "        # stack the image features\n",
    "        stackedFeatures = torch.cat((imgFeatures1, imgFeatures2), 1)\n",
    "        #print(stackedFeatures.shape)\n",
    "        \n",
    "        \n",
    "        netOutput = self.outputLinear(stackedFeatures)\n",
    "        #print(netOutput.shape)\n",
    "        \n",
    "        return torch.sigmoid(netOutput)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b1143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = movingNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e3a31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movingDataLoader = DataLoader(data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa89f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(movingDataLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "625608da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 800, 36])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['frame1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b942fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4907],\n",
       "        [0.4922],\n",
       "        [0.4925],\n",
       "        [0.4918],\n",
       "        [0.4910],\n",
       "        [0.4913],\n",
       "        [0.4912],\n",
       "        [0.4912],\n",
       "        [0.4925],\n",
       "        [0.4914],\n",
       "        [0.4905],\n",
       "        [0.4925],\n",
       "        [0.4919],\n",
       "        [0.4916],\n",
       "        [0.4907],\n",
       "        [0.4923]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(sample['frame1'], sample['frame2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2721189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['cellsmoving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "974f2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9632b6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6696ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "        \n",
    "    if weights is not None:\n",
    "        assert len(weights) == 2\n",
    "        \n",
    "        loss = weights[1] * (target * torch.log(output)) + \\\n",
    "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "        \n",
    "    #print(loss)\n",
    "    return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6266ca",
   "metadata": {},
   "source": [
    "### Train and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46fff73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 avg loss: 1.2029531142290901\n",
      "Epoch: 2 avg loss: 0.7996154427528381\n",
      "Epoch: 3 avg loss: 0.6629438365206999\n",
      "Epoch: 4 avg loss: 0.6002627646221834\n",
      "Epoch: 5 avg loss: 0.5528471592594596\n",
      "Epoch: 6 avg loss: 0.468210328151198\n",
      "Epoch: 7 avg loss: 0.40848353329826803\n",
      "Epoch: 8 avg loss: 0.49995168517617616\n",
      "Epoch: 9 avg loss: 0.3724890903514974\n",
      "Epoch: 10 avg loss: 0.36458728330976825\n",
      "Epoch: 11 avg loss: 0.3115284881171058\n",
      "Epoch: 12 avg loss: 0.30505984846283407\n",
      "Epoch: 13 avg loss: 0.2989852726459503\n",
      "Epoch: 14 avg loss: 0.2760763069724335\n",
      "Epoch: 15 avg loss: 0.30264050601159825\n",
      "Epoch: 16 avg loss: 0.29055747915716734\n",
      "Epoch: 17 avg loss: 0.2633880683604409\n",
      "Epoch: 18 avg loss: 0.22958366923472462\n",
      "Epoch: 19 avg loss: 0.25274987168171825\n",
      "Epoch: 20 avg loss: 0.20838351854506662\n",
      "Epoch: 21 avg loss: 0.20352498989771395\n",
      "Epoch: 22 avg loss: 0.22168895865187926\n",
      "Epoch: 23 avg loss: 0.19294397773988106\n",
      "Epoch: 24 avg loss: 0.21211347707054196\n",
      "Epoch: 25 avg loss: 0.17526479722822413\n",
      "Epoch: 26 avg loss: 0.20104949943283024\n",
      "Epoch: 27 avg loss: 0.20170429611907287\n",
      "Epoch: 28 avg loss: 0.16915023020085165\n",
      "Epoch: 29 avg loss: 0.16054443905458732\n",
      "Epoch: 30 avg loss: 0.13913007474997463\n",
      "Epoch: 31 avg loss: 0.1357988257180242\n",
      "Epoch: 32 avg loss: 0.16200951684047193\n",
      "Epoch: 33 avg loss: 0.12477660288705546\n",
      "Epoch: 34 avg loss: 0.1124165222487029\n",
      "Epoch: 35 avg loss: 0.11115592498989667\n",
      "Epoch: 36 avg loss: 0.18226466075900724\n",
      "Epoch: 37 avg loss: 0.14503547176718712\n",
      "Epoch: 38 avg loss: 0.1669333439101191\n",
      "Epoch: 39 avg loss: 0.11691297185333337\n",
      "Epoch: 40 avg loss: 0.08086892896715332\n",
      "Epoch: 41 avg loss: 0.08569466300746974\n",
      "Epoch: 42 avg loss: 0.08244223366765414\n",
      "Epoch: 43 avg loss: 0.10548230611226138\n",
      "Epoch: 44 avg loss: 0.09601019996711437\n",
      "Epoch: 45 avg loss: 0.06966427275363136\n",
      "Epoch: 46 avg loss: 0.09945168357123346\n",
      "Epoch: 47 avg loss: 0.0718407860464033\n",
      "Epoch: 48 avg loss: 0.08092927028808523\n",
      "Epoch: 49 avg loss: 0.06114970925537979\n",
      "Epoch: 50 avg loss: 0.08111814719022196\n"
     ]
    }
   ],
   "source": [
    "batch_size = 48\n",
    "nEpochs = 50\n",
    "phaseDirectoriesList = ['/home/pk/Documents/trainingData/deadalive1/' + str(i) + '/' for i in range(0, 19)]\n",
    "data = cellsMovingDataset(phaseDirectoriesList, transforms = randomTranslations())\n",
    "movingDataLoader = DataLoader(data, batch_size=batch_size, num_workers=6, shuffle=True)\n",
    "net = movingNet()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=5e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "for epoch in range(nEpochs):\n",
    "    \n",
    "    epochLoss = []\n",
    "    \n",
    "    for i_batch, data in enumerate(movingDataLoader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        img1, img2 = data['frame1'].to(device), data['frame2'].to(device)\n",
    "        output = net(img1, img2)\n",
    "        target = data['cellsmoving'].to(device)\n",
    "        #print(output)\n",
    "        #print(target)\n",
    "        loss = weighted_binary_cross_entropy(output, target,weights=[771/588, 771/193])\n",
    "        #print(loss)\n",
    "        epochLoss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    print(f\"Epoch: {epoch + 1} avg loss: {np.mean(epochLoss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33fe1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "phaseDirectoriesList = ['/home/pk/Documents/trainingData/deadalive1/' + str(i) + '/' for i in range(0, 19)]\n",
    "data = cellsMovingDataset(phaseDirectoriesList, transforms = randomTranslations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c73c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moved': 193, 'notmoved': 588}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535fa04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "588 + 183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e28ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel = {\n",
    "    'model_state_dict': net.state_dict()\n",
    "}\n",
    "savedPath = '/home/pk/Documents/models/moving.pth'\n",
    "torch.save(savedModel, savedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f0e8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1abe5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNet(dataDir, modelPath, fileformat='.tiff', plot=False):\n",
    "        \n",
    "    # net intializee and run\n",
    "    net = movingNet()\n",
    "    saved_net_parameters = torch.load(modelPath)\n",
    "    net.load_state_dict(saved_net_parameters['model_state_dict'])\n",
    "    net.eval()\n",
    "    \n",
    "    filenames = [int(filename.split('.')[0].split('/')[-1]) \n",
    "             for filename in glob.glob(dataDir + \"*\"+ fileformat)]\n",
    "    filenames.sort()\n",
    "    sortedFilenames = [dataDir + str(filenumber) + fileformat for filenumber in filenames]\n",
    "    print(sortedFilenames)\n",
    "    \n",
    "    imgTransforms = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    predicted_states =[]\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sortedFilenames) - 1):\n",
    "            img1 = io.imread(sortedFilenames[i])\n",
    "            img2 = io.imread(sortedFilenames[i+1])\n",
    "            \n",
    "            img1 = imgTransforms(img1).unsqueeze(0)\n",
    "            img2 = imgTransforms(img2).unsqueeze(0)\n",
    "            output = net(img1, img2) > 0.5\n",
    "            print(output.item())\n",
    "            predicted_states.append(output.item())\n",
    "            \n",
    "    \n",
    "    \n",
    "    if plot == True:\n",
    "        states = np.array(predicted_states).T\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "        img = io.imread(sortedFilenames[0])\n",
    "\n",
    "        tdata, movingdata, = [], []\n",
    "        movingplot, = ax[1].plot([], [], 'g,:', label='Moving')\n",
    "        #partialdeadplot, = ax[1].plot([], [], 'r,-.', label='Partial Dead')\n",
    "        #alldeadplot, = ax[1].plot([], [], 'k--', label='All Dead')\n",
    "        #nocellsplot, = ax[1].plot([], [], 'b*', label='No cells')\n",
    "        #cellsvanishplot, = ax[1].plot([], [], 'mo', label='Cells vanish')\n",
    "\n",
    "\n",
    "        imgplot = ax[0].imshow(img, cmap='gray')\n",
    "\n",
    "\n",
    "        def init():\n",
    "            img = io.imread(sortedFilenames[0])\n",
    "            imgplot.set_array(img)\n",
    "            ax[1].set_xlim([0, len(sortedFilenames)])\n",
    "            ax[1].set_ylim([-0.5, 2])\n",
    "            return imgplot, \n",
    "\n",
    "        def update(frame):\n",
    "\n",
    "            img = io.imread(sortedFilenames[frame])\n",
    "            imgplot.set_array(img)\n",
    "            tdata.append(frame)\n",
    "            movingdata.append(int(states[0][frame]))\n",
    "            movingplot.set_data(tdata, movingdata) \n",
    "\n",
    "            partialdeaddata.append(int(states[2][frame]))\n",
    "            partialdeadplot.set_data(tdata, partialdeaddata)\n",
    "\n",
    "            alldeaddata.append(int(states[3][frame]))\n",
    "            alldeadplot.set_data(tdata, alldeaddata)\n",
    "\n",
    "            nocellsdata.append(int(states[4][frame]))\n",
    "            nocellsplot.set_data(tdata, nocellsdata)\n",
    "\n",
    "            cellsvanishdata.append(int(states[5][frame]))\n",
    "            cellsvanishplot.set_data(tdata, cellsvanishdata)\n",
    "\n",
    "\n",
    "            return [imgplot, movingplot, partialdeadplot,]\n",
    "\n",
    "        ani = FuncAnimation(fig, update, frames=range(0, len(sortedFilenames)),\n",
    "                            init_func=init, blit=False, repeat=False, interval=1000)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "        \n",
    "    return None, predicted_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30a71716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/pk/Documents/trainingData/deadalive1/28/0.tiff', '/home/pk/Documents/trainingData/deadalive1/28/1.tiff', '/home/pk/Documents/trainingData/deadalive1/28/2.tiff', '/home/pk/Documents/trainingData/deadalive1/28/3.tiff', '/home/pk/Documents/trainingData/deadalive1/28/4.tiff', '/home/pk/Documents/trainingData/deadalive1/28/5.tiff', '/home/pk/Documents/trainingData/deadalive1/28/6.tiff', '/home/pk/Documents/trainingData/deadalive1/28/7.tiff', '/home/pk/Documents/trainingData/deadalive1/28/8.tiff', '/home/pk/Documents/trainingData/deadalive1/28/9.tiff', '/home/pk/Documents/trainingData/deadalive1/28/10.tiff', '/home/pk/Documents/trainingData/deadalive1/28/11.tiff', '/home/pk/Documents/trainingData/deadalive1/28/12.tiff', '/home/pk/Documents/trainingData/deadalive1/28/13.tiff', '/home/pk/Documents/trainingData/deadalive1/28/14.tiff', '/home/pk/Documents/trainingData/deadalive1/28/15.tiff', '/home/pk/Documents/trainingData/deadalive1/28/16.tiff', '/home/pk/Documents/trainingData/deadalive1/28/17.tiff', '/home/pk/Documents/trainingData/deadalive1/28/18.tiff', '/home/pk/Documents/trainingData/deadalive1/28/19.tiff', '/home/pk/Documents/trainingData/deadalive1/28/20.tiff', '/home/pk/Documents/trainingData/deadalive1/28/21.tiff', '/home/pk/Documents/trainingData/deadalive1/28/22.tiff', '/home/pk/Documents/trainingData/deadalive1/28/23.tiff', '/home/pk/Documents/trainingData/deadalive1/28/24.tiff', '/home/pk/Documents/trainingData/deadalive1/28/25.tiff', '/home/pk/Documents/trainingData/deadalive1/28/26.tiff', '/home/pk/Documents/trainingData/deadalive1/28/27.tiff', '/home/pk/Documents/trainingData/deadalive1/28/28.tiff', '/home/pk/Documents/trainingData/deadalive1/28/29.tiff', '/home/pk/Documents/trainingData/deadalive1/28/30.tiff', '/home/pk/Documents/trainingData/deadalive1/28/31.tiff', '/home/pk/Documents/trainingData/deadalive1/28/32.tiff', '/home/pk/Documents/trainingData/deadalive1/28/33.tiff', '/home/pk/Documents/trainingData/deadalive1/28/34.tiff', '/home/pk/Documents/trainingData/deadalive1/28/35.tiff', '/home/pk/Documents/trainingData/deadalive1/28/36.tiff', '/home/pk/Documents/trainingData/deadalive1/28/37.tiff', '/home/pk/Documents/trainingData/deadalive1/28/38.tiff', '/home/pk/Documents/trainingData/deadalive1/28/39.tiff']\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "phaseDir = '/home/pk/Documents/trainingData/deadalive1/28/'\n",
    "modelPath = '/home/pk/Documents/models/moving.pth'\n",
    "ani, predicted_states = testNet(phaseDir, modelPath, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a7b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109baabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fdc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777c068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946399b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93e5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea13f03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]], device='cuda:1')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9adccdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], device='cuda:1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912208dd",
   "metadata": {},
   "source": [
    "### Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1bfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
